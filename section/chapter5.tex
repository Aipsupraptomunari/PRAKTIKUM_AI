\chapter{Conclusion}
brief of conclusion

\section{Conclusion of Problems}
Tell about solving the problem

\section{Conclusion of Method}
Tell about solving using method

\section{Conclusion of Experiment}
Tell about solving in the experiment

\section{Conclusion of Result}
tell about result for purpose of this research.

\section{Andi Muh Aslam/1164064}
\subsection{Teori}
\begin{enumerate}
\item Jelaskan Kenapa Kata-Kata harus dilakukan vektorisasi lengkapi dengan ilustrasi gambar.
\subitem Kata-kata harus dilakukan vektorisasi untuk mengukur nilai kemunculan suatu kata agar dapat di prediksi atau untuk menentukan bobot suatu kata.
\par Untuk ilustrasinya dapat dilihat pada gambar
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/L1.PNG}}
	\caption{Ilustrasi Soal No.1}
\end{figure}

\item Jelaskan Mengapa dimensi dari vektor dataset google bisa mencapai 300 lengkapi dengan ilustrasi gambar.
\subitem Dimensi dari vektor dataset google dapat mencapai 300 karena dimensi pada vektor agar dapat membandingkan bobot dari kata tersebut, misalkan terdapat kata Jaket dan Tas pada data set google setiap kata tersebut di buat dimensi vektor senilai 300 kata Jaket dan 300 kata Tas, agar dapat membandingkan bobot dari kesamaan kata Jaket dan Tas. 
\par Untuk ilustrasinya dapat dilihat pada gambar 
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/L2.PNG}}
	\caption{Ilustrasi Soal No. 2}
	
\end{figure}

\item Jelaskan Konsep vektorisasi untuk kata . dilengkapi dengan ilustrasi atau gambar.
\subitem Konsep dari vektorisasi kata yaitu agar dapat mengetahui kata tengah pada kalimat utama, Contoh ( Subscribe channel ini dan Like yah Guys ). Kata tengah dari contoh tersebut merupakan (dan) yang memiliki bobot sebagai kata tengah dari kalimat. Hal ini sangat berkaitan dengan dimensi vektor pada dataset google karena memiliki nilai atau bobot kata tengah.
\par Untuk ilustrasinya dapat dilihat pada gambar \begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/L3.PNG}}
	\caption{Ilustrasi Soal No. 3}
	
\end{figure}
\item Jelaskan Konsep vektorisasi untuk dokumen. dilengkapi dengan ilustrasi atau gambar.
\subitem Konsep vektorisasi pada dokumen mesin akan membaca kata-kata terlebih dahulu pada semua kalimat yang ada di dalam dokumen dan nanti kalimat yg ada di dalam dokumen akan dipecah menjadi kata-kata.
\par Untuk ilustrasinya dapat dilihat pada gambar 
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/L4.PNG}}
	\caption{Ilustrasi Soal No. 4}
	
\end{figure}

\item Jelaskan apa mean dan standar deviasi, lengkapi dengan iludtrasi atau gambar.
\subitem Mean merupakan nilai rata-rata yang tingkat akurasinya tinggi atau nilai tersebut sering munucul. Standar deviasi mengukur bagaimana nilai-nilai data tersebar. Bisa juga didefinisikan sebagai, rata-rata jarak penyimpangan titik-titik data diukur dari nilai rata-rata data tersebut.
\par Untuk ilustrasinya dapat dilihat pada gambar 
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/L5.PNG}}
	\caption{Ilustrasi Soal No. 5}
	
\end{figure}

\item Jelaskan Apa itu Skip-Gram sertakan contoh ilustrasi.
\subitem Skip-Gram yaitu dimana kata tengah menjadi acuan terhadap kata kata pelengkap dalam suatu kalimat.
\par Untuk ilustrasinya dapat dilihat pada gambar 
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/L6.PNG}}
	\caption{Ilustrasi Soal No. 6}
	
\end{figure}
\end{enumerate}

\subsection{Praktek Program}
\begin{enumerate}
\item Cobalah dataset google, dan jelaskan vektor dari kata love, faith, fall, sick, clear, shine, bag, car, wash, motor, cycle dan cobalah untuk melakukan perbandingan similirati dari masing-masing kata tersebut. Jelaskan arti dari outputan similaritas.
\subitem Output source code dibawah akan memunculkan data vektor untuk kata love. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar.
\begin{verbatim}
gmodel['love']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E1.PNG}}
	\caption{Love}
	\label{c5_7}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata faith. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_8}.
\begin{verbatim}
gmodel['faith']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E2.PNG}}
	\caption{Faith}
	\label{c5_8}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata fall. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_9}.
\begin{verbatim}
gmodel['fall']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E3.PNG}}
	\caption{Fall}
	\label{c5_9}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata sick. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_10}.
\begin{verbatim}
gmodel['sick']
\end{verbatim}

\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E4.PNG}}
	\caption{Sick}
	\label{c5_10}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata clear. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_11}.
\begin{verbatim}
gmodel['clear']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E5.PNG}}
	\caption{Clear}
	\label{c5_11}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata shine. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_12}.
\begin{verbatim}
gmodel['shine']
\end{verbatim}

\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E6.PNG}}
	\caption{Shine}
	\label{c5_12}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata bag. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_13}.
\begin{verbatim}
gmodel['bag']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E7.PNG}}
	\caption{Bag}
	\label{c5_13}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata car. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_14}.
\begin{verbatim}
gmodel['car']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E8.PNG}}
	\caption{Car}
	\label{c5_14}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata wash. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_15}.
\begin{verbatim}
gmodel['wash']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E9.PNG}}
	\caption{Wash}
	\label{c5_15}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata motor. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_16}.
\begin{verbatim}
gmodel['motor']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E10.PNG}}
	\caption{Motor}
	\label{c5_16}
\end{figure}
\subitem Output source code dibawah akan memunculkan data vektor untuk kata cycle. bahwa vektor memiliki array sebanyak 300 dimensi. Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_17}.
\begin{verbatim}
gmodel['cycle']
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E11.PNG}}
	\caption{Cycle}
	\label{c5_17}
\end{figure}
\subitem Pada source code dibawah menunjukkan hasil score perbandingan kata apakah kata motor dan cycle memiliki ke samaan atau tidak.  Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_18}.
\begin{verbatim}
gmodel.similarity('motor','cycle')
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E12.PNG}}
	\caption{Similariti Pada Kata Motor dan Cycle}
	\label{c5_18}
\end{figure}
\subitem Pada source code dibawah menunjukkan hasil score perbandingan kata apakah kata wash dan motor memiliki ke samaan atau tidak.  Hasil pada source code tersebut dapat dilihat pada gambar \ref{c5_19}.
\begin{verbatim}
gmodel.similarity('wash','motor')
\end{verbatim}
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E13.PNG}}
	\caption{Similariti Pada Kata Wash dan Motor}
	\label{c5_19}
\end{figure}
\subitem Untuk Motor dan Cycle hasilnya adalah 17\%
\subitem Untuk Wash dan Motor hasilnya adalah 10\%
\subitem Artinya Motor dan Cyle memang dalam kategori yang sama misalnya dalam kategori kata-kata yang disatukan/berpasangan. Mesin sudah mengetahui bahwa keduanya dapat dikategorikan sebagai sepasang kata.
\item Jelaskan dengan kata dan ilustrasi fungsi dari extract\_words dan PermuteSentences.
\subitem Extract\_Words merupakan function untuk menambahkan, menghilangkan atau menghapuskan, hal hal yang tidak penting atau tidak perlu di dalam teks. Pada gambar \ref{c5_20} berikut ini menggunakan function extract\_words untuk menghapus komen dengan python style , mencari data yang diinginkan, dan memberikan spasi pada teks.
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E14.PNG}}
	\caption{Extract\_Words}
	\label{c5_20}
\end{figure}
\subitem PermuteSentences berfungsi untuk melakukan pengacakan data supaya memperoleh data yang teratur. Ini merupakan class yang digunakan untuk melakukan pengocokan secara acak pada data yang ada. Digunakan cara ini agar tidak terjadi kelebihan memori pada saat dijalankan. Hasilnya dapat dilihat pada gambar \ref{c5_21}.
\begin{figure}[ht]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/E15.PNG}}
	\caption{Permute Sentences}
	\label{c5_21}
\end{figure}

\item Jelaskan fungsi dari librari gensim TaggedDocument dan Doc2Vec disertai praktek pemakaiannya.
\subitem Fungsi dari library gensim yaitu sebagai pemodelan topik tanpa pengawasan dan pemrosesan bahasa alami, atau bisa kita sebut dengan unsupervised.  tagged document itu sendiri untuk memasukan kata-kata pada setiap dokumennya yang akan di vektorisasi. Fungsi dari doc2vec itu sendiri ialah untuk membandingkan bobot data yang terdapat pada dokumen lainnya, apakah kata-kata didalamnya ada yang sama atau tidak. Ketika di running maka tidak terjadi apa-apa, seperti pada gambar \ref{c5_22}
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T1.PNG}}
	\caption{Gensim TaggedDocument dan Doc2vec}
	\label{c5_22}
\end{figure}
\item Jelaskan dengan kata dan praktek cara menambahkan data training dari file yang dimasukkan kepada variabel dalam rangka melatih model doc2vec.
\subitem Untuk menambahkan data training yaitu melakukan import library os, library os berfungsi untuk melakukan interaksi antara python dengan os laptop kita masing-masing, setelah itu kita buat variabel unsup sentences. Kemudian pilih direktori tempat data kita disimpan. Lalu menyortir data yang terdapat pada folder aclImdb dan membaca file tersebut dengan ektensi .txt.
\begin{verbatim}
import os
unsup_sentences = []
for dirname in ["train/pos","train/neg","train/unsup","test/pos","test/neg"]:
for fname in sorted(os.listdir("aclImdb/"+dirname)):
if fname[-4:] == '.txt':
with open("aclImdb/"+dirname+"/"+fname,encoding='UTF-8') as f:
sent = f.read()
words = extract_words(sent)
unsup_sentences.append(TaggedDocument(words,[dirname+"/"+fname]))
\end{verbatim}
\subitem Hasil dari code yang diatas ialah terdapatnya data training dengan jumlah 10000 data dari variabel unsup\_sentences hasil running dari folder aclImdb dapat dilihat pada gambar 
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T2.PNG}}
	\caption{Aclimbdb}
	\end{figure}

\begin{verbatim}
for dirname in ["review_polarity/txt_sentoken/pos","review_polarity/txt_sentoken/neg"]:
for fname in sorted(os.listdir(dirname)):
if fname[-4:] == '.txt':
with open(dirname+"/"+fname,encoding='UTF-8') as f:
for i, sent in enumerate(f):
words = extract_words(sent)
unsup_sentences.append(TaggedDocument(words,["%s/%s-%d" % (dirname,fname,i)]))
\end{verbatim}
\subitem Untuk code berikutnya akan menambahkan data training pada variabel unsup\_sentences sekitar 64.720 data, seperti pada gambar 
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T3.PNG}}
	\caption{Aclimbdb}
\end{figure}

\begin{verbatim}
with open("stanfordSentimentTreebank/original_rt_snippets.txt",encoding='UTF-8') as f:
for i, sent in enumerate(f):
words = extract_words(sent)
unsup_sentences.append(TaggedDocument(words,["rt-%d" % i]))
\end{verbatim}
\subitem Untuk code berikutnya akan menambahkan data training pada variabel unsup\_sentences sekitar 10.605 data, seperti pada gambar 
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T4.PNG}}
	\caption{Aclimbdb}
\end{figure}

\item Jelaskan dengan kata dan praktek kenapa harus dilakukan pengocokan dan pembersihan data.
\subitem Pengocokan data itu berguna untuk mengacak data supaya pada saat data di running bisa berjalan lebih baik dan hasil presentase akhirnya bisa lebih bagus. Sedangkan pembersihan data untuk memberikan ruang bagi ram komputer kita setelah melakukan running data sebanyak 3 juta lebih, agar lebih ringan saat proses selanjutnya. Hasil dari pengacakan data tidak ditampilkan pada spyder. Dan sebelumnya memori yang terpakai itu sekitar 87\% , setelah dikosongkan jadi 71\%. Untuk source codenya dapat dilihat sebagai berikut:
\begin{verbatim}
# Pengocokan data
mute = PermuteSentences(unsup_sentences)
# Pembersihan data
model.delete_temporary_training_data(keep_inference=True)
\end{verbatim}
\item Jelaskan dengan kata dan praktek kenapa model harus di save dan kenapa temporari training harus dihapus.
\subitem Save data untuk menyimpan file hasil dari proses training data sebelumnya, model tersebut dilakukan penyimpanan untuk memberikan keringanan pada ram agar saat kita akan melakukan training lagi, model tersebut tinggal di muat saja tanpa harus melakukan traning dari awal dan bisa menghemat waktu. Sedangkan untuk delete temporary training data untuk menghapus data training yang sebelumnya sudah dilakukan dan disimpan, tujuannya memberikan keringanan pada ram. Karena setelah melakukan proses training, ram biasanya jadi berat untuk membaca sampai komputer kita jadi lemot. Untuk source codenya dapat dilihat sebagai berikut:
\begin{verbatim}
# Save data
model.save('ocean.d2v')
# Delete temporary data
model.delete_temporary_training_data(keep_inference=True)
\end{verbatim}
\item Jalankan dengan kata dan praktek maksud dari infer code.
\subitem Infer vector yaitu membandingkan kata yang tercantum dengan vektor pada dokumen yang sudah di muat sebelumnya. Selain itu infer\_vector juga menghitung vektor dari kata yang dicantumkan pada model yang telah kita buat. Seharusnya kata yang dicantumkan itu lebih panjang lagi agar hasilnya bisa lebih baik lagi.
\begin{verbatim}
model.infer_vector(extract_words("I will go home"))
\end{verbatim}
\subitem Pada source code tersebut menghasilkan keluaran seperti pada gambar.
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T5.PNG}}
	\caption{Infer Code}
\end{figure}

\item Jelaskan dengan praktek dan kata maksud dari cosine similarity.
\subitem Cosine similarity yaitu membandingkan vektorisasi data diantara kedua kata yang di masukkan, Jika hasil presentase dari kedua kata tersebut lebih dari 50 persen kemungkinan kata tersebut terdapat dalam 1 file. Tapi jika kurang dari 50 persen kata tersebut tidak terdapat dalam 1 file. Hasil yang didapatkan pada code tersebut hanya 0.4 persen itu dikarenakan kata pertama dan kedua tidak memiliki kesamaan vektorisasi dan tidak terdapat pada salah satu dokumen.
\begin{verbatim}
from sklearn.metrics.pairwise import cosine_similarity
cosine_similarity(
[model.infer_vector(extract_words("she going to school, after wash hand"))],
[model.infer_vector(extract_words("Services sucks."))])
\end{verbatim}
\subitem Pada source code tersebut menghasilkan keluaran seperti pada gambar
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T6.PNG}}
	\caption{Cosine Similarity}
\end{figure}

\item Jelaskan dengan praktek score dari cross validation masing-masing metode.
\subitem score dari cross validation yang mana mengecek data score KNN untuk menghasilkan typedata float64 dimana terdapat 5 data dari score yang typedatanya float64 tersebut. Dan disini menggunakan metode clf
\begin{verbatim}
scores = cross_val_score(clf, sentvecs, sentiments, cv=5)
np.mean(scores), np.std(scores)
\end{verbatim}
\subitem Pada source code tersebut menghasilkan keluaran seperti pada gambar 
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T7.PNG}}
	\caption{Cross Validation Metode 1}
\end{figure}

\begin{verbatim}
scores = cross_val_score(clfrf, sentvecs, sentiments, cv=5)
np.mean(scores), np.std(scores)
\end{verbatim}
\subitem Pada source code tersebut mengecek data score RF dengan menggunakan metode clfrf yang menghasilkan keluaran seperti pada gambar 
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T8.PNG}}
	\caption{Cross Validation Metode 2}
\end{figure}

\begin{verbatim}
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), RandomForestClassifier())
scores = cross_val_score(pipeline,sentences,sentiments, cv=5)
np.mean(scores), np.std(scores)
\end{verbatim}
\subitem Pada source code tersebutcmelakukan skoring dari vektorisasi, tfidf, dan rf lalu dibuat perbandingan yang menghasilkan keluaran seperti pada gambar 
\begin{figure}[!htbp]
	\centerline{\includegraphics[width=1\textwidth]{figures/andi/T9.PNG}}
	\caption{Cross Validation Metode 3}
\end{figure}
\end{enumerate}


\section{Aip Suprapto Munari/1164063}
\subsection{Teori}
\begin{enumerate}

\item Mengapa Kata-Kata Harus di Vektorisasi
\par Kata harus divektorisasi karena mesin hanya mampu membaca data dalam tipe/bentuk angka. Oleh sebab itu, diperlukannya vektorisasi kata untuk mampu mebaca data tersebut. 
\par
\begin{itemize}
\item Gambar :
\par Penjelasan : Berdasarkan pengertian diatas, ada beberapa contoh yang bisa diterapkan. Untuk salah satu contoh dari klasifikasi data sendiri dapat diliat pada gambar berikut \ref{vektorisasikata}.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.6]{figures/AIP/d1.PNG}
\caption{Vektorisasi Kata Aip}
\label{text-Aip}
\end{figure}
\end{itemize}

\item Mengapa Dimensi Dari Vektor Dataset Google Bisa Sampai 300
\par Setiap nilai dalam vektor 300 dimensi yang terkait dalam sebuah kata "dioptimalkan" dalam  beberapa hal untuk menangkap aspek yang  berbeda. Dengan kata lain masing-masing dari 300 nilai sesuai dengan beberapa fitur abstrak kata. Menghapus kombinasi nilai-nilai ini secara acak akan menghasilkan vektor yang mungkin kurang informasi penting tentang kata tersebut dan mungkin tidak lagi berfungsi sebagai representasi yang baik dari kata itu. Atau singkat cerita mungkin ada lebih dari 3 miliar kata-kata dan kalimat atau data yang tidak mungkin disimpan dalam 1 dimensi vektor maka disimpan menjadi 300 dimensi vektor untuk mengurangi kegagalan memori.
\par
\begin{itemize}
\item Gambar :
\par Penjelasan : Berdasarkan pengertian diatas, ada beberapa contoh yang bisa diterapkan. Untuk salah satu contoh dari klasifikasi data sendiri dapat diliat pada gambar berikut \ref{googleDataset}.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.16]{figures/AIP/d2.PNG}
\caption{Google Dataset Aip}
\label{text-Aip}
\end{figure}
\end{itemize}

\item Konsep Vektorisasi Kata 
\par Konsep vektorisasi data merupakan kata-kata yang di inputkan pada mesin learning. Dan outputan nya berupa kara-kata atau keyword dari pencarian yang telah di lakukan sebelumnya. Contoh nya pada saat kita melakukan pencarian di youtube maupun pencarian google. Maka akan muncul hasil dari pencarian dari kata-kata yang telah kita cari atau input.
\par
\begin{itemize}
\item Gambar :
\par Penjelasan : Berdasarkan pengertian diatas, ada beberapa contoh yang bisa diterapkan. Untuk salah satu contoh dari klasifikasi data sendiri dapat diliat pada gambar berikut \ref{vekktorisasikata}.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/d1.PNG}
\caption{Vektorisasi Kata Aip}
\label{text-Aip}
\end{figure}
\end{itemize}

\item Konsep Vektorisasi Dokumen 
\par Konsep vektorisasi dokumen yaitu mesin akan membaca terlebih dahulu semua kalimat yang berada pada dalam dokumen dan nanti kalimat tersebut akan di pecah menjadi kata-kata.
\par
\begin{itemize}
\item Gambar :
\par Penjelasan : Berdasarkan pengertian diatas, ada beberapa contoh yang bisa diterapkan. Untuk salah satu contoh dari klasifikasi data sendiri dapat diliat pada gambar berikut \ref{vektorisasidokumen}.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/d3.PNG}
\caption{Vektorisasi Dokumen Aip}
\label{text-Aip}
\end{figure}
\end{itemize}

\item Mean dan Standar Deviasi
\par Mean adalah teknik penjelasan kelompok yang didasarkan atas nilai rata-rata dari kelompok tersebut. Rata-Rata (mean) ini didapat dengan menjumlahkan data seluruh individu dalam kelompok itu, kemudian dibagi dengan jumlah individu yang ada pada kelompok tersebut. Standar deviasi adalah nilai statistik yang digunakan untuk menentukan bagaimana sebaran data dalam sampel, dan seberapa dekat titik data individu ke mean atau rata-rata nilai sampel.Sebuah standar deviasi dari kumpulan data sama dengan nol menunjukkan bahwa semua nilai-nilai dalam himpunan tersebut adalah sama. Sebuah nilai deviasi yang lebih besar akan memberikan makna bahwa titik data individu jauh dari nilai rata-rata.
\par
\begin{itemize}
\item Gambar :
\par Penjelasan : Berdasarkan pengertian diatas, ada beberapa contoh yang bisa diterapkan. Untuk salah satu contoh dari klasifikasi data sendiri dapat diliat pada gambar berikut \ref{mean dan Standar Deviasi}.
\begin{figure}
\centering
\includegraphics[scale=0.2]{figures/AIP/d4.PNG}
\caption{Mean Aip}
\label{text-Aip}
\end{figure}
\begin{figure}[ht]
\centering
\includegraphics[scale=0.2]{figures/AIP/d5.PNG}
\caption{Standar Deviasi Aip}
\label{text-Aip}
\end{figure}
\par
\end{itemize}

\item Skip Gram
\par Skip-Gram mencoba memprediksi vektor kata-kata yang ada di konteks diberikan vektor kata tertentu. Skip-gram membuat sepasang kata target dan konteks sebagai sebuah instance.
\par
\begin{itemize}
\item Gambar :
\par Penjelasan : Berdasarkan pengertian diatas, ada beberapa contoh yang bisa diterapkan. Untuk salah satu contoh dari klasifikasi data sendiri dapat diliat pada gambar berikut \ref{skipgram}.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.2]{figures/AIP/d6.PNG}
\caption{Skip-Gram Aip}
\label{text-Aip}
\end{figure}
\end{itemize}
\end{enumerate}


\section{PRAKTEK PROGRAM}
\section{Aip Suprapto Munari/1164063}
\subsection{Mencoba Dataset}
\subsubsection{Vektor}
\begin{itemize}
\item Pada gambar diatas dapat dilihat bahwa vektor memiliki array sebanyak 300 dimensi. Untuk identitas sektor satu adalah 0.080
\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/AIP/e4.PNG}
\caption{Vektor Love Aip}
\label{Praktek}
\end{figure}


\item Pada gambar diatas untuk vektor faith dapat dilihat memliki nilai 0.049 , untuk similaritasnya cukup mendekati vektor love dimana faith dapat dikategorikan dalam satu kategori dengan love.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/AIP/e5.PNG}
\caption{Vektor Faith Aip}
\label{Praktek}
\end{figure}


\item Vektor fall hanya memiliki nilai yaitu 0.046, dimana mesin memahami bahwa fall terdapat dalam satu kategori yang sama dengan  faith.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/AIP/e6.PNG}
\caption{Vektor Fall Aip}
\label{Praktek}
\end{figure}


\item  Vektor sick memiliki nilai identitas 0.085 dimana mendekati love.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/AIP/e7.PNG}
\caption{Vektor Sick Aip}
\label{Praktek}
\end{figure}


\item Vektor clear memiliki nilai identitas -0,025 dan tidak mendekati nilai dari vektor manapun sehingga tidak dapat dijadikan dalam satu kategori.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e8.PNG}
\caption{Vektor Clear Aip}
\label{Praktek}
\end{figure}

\item Untuk vektor shine 0.35 mendekati vektor Faith dan fall.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e9.PNG}
\caption{Vektor Shine Aip}
\label{Praktek}
\end{figure}


\item Vektor bag memiliki i=nilai identitas 0.026 yang mendekati dengan vektor fall dan faith. Sehingga mesin memahami bahwa mungkin saja kedua vektor tersebut berada dalam satu kategori.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e10.PNG}
\caption{Vektor Bag Aip}
\label{Praktek}
\end{figure}


\item Vektor car nilainya 0.48 tidak ada yang mendekati vektor manapun sehingga tidak dapat dikategorikan dalam satu kategori.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e11.PNG}
\caption{Vektor Car Aip}
\label{Praktek}
\end{figure}


\item Vektor wash memiliki nilai 0.102 jauh dari vektor vektor lainnya.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e12.PNG}
\caption{Vektor Wash Aip}
\label{Praktek}
\end{figure}


\item Vektor cycle memiliki nilai identitas 0.179 yang bisa mendekati vektor wash. Dapat dikatakan bahwa motor dapat dicuci jika diarti dalam satu kategori yang sama.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e14.PNG}
\caption{Vektor cycle Aip}
\label{Praktek}
\end{figure}
\end{itemize}

\subsubsection{Similariti}
\begin{enumerate}
\item Lihat gambar berikut yang merupakan hasil prediksi similariti
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e17.PNG}
\caption{Similariti Aip}
\label{Praktek}
\end{figure}

Dapat disimpulkan bahwa
\begin{itemize}
\item Untuk Motor dan faith hasilnya adalah 0.049
\item Untuk Motor dan fall hasilnya adalah 0.046
\item Untuk Motor dan clear hasilnya adalah -0.025
\item Untuk Motor dan wash hasilnya adalah 0.102
\item Untuk Motor dan cycle hasilnya adalah 0.179
\item Artinya Motor dan cycle memang dalam kategoriy ang sama misalnya dalam kategori kendaraan. Mesin sudah mengetahui bahwa keduanya dapat dikategorikan sebagai kendaraan.
\end{itemize}
\end{enumerate}

\subsection{Extract Words dan PermuteSentences}
\subsubsection{Extract Words}
ExtractWords merupakan function untuk menambahkan, menghilangkan atau menghapuskan, hal hal yang tidak penting atau tidak perlu di dalam teks. Dalam contoh dibawah ini. menggunakan function extract words untuk menghapus komen dengan python style , mencari data yang diinginkan, dan memberikan spasi pada teks.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e15.PNG}
\caption{Extract Words Aip}
\label{Praktek}
\end{figure}

\subsubsection{PermuteSentences}
PermuteSentences merupakan class yang digunakan untuk melakukan pengocokan secara acak pada data yang ada. Digunakan cara ini agar tidak terjadi kelebihan memori pada saat dijalankan. Contoh dibawah yaitu fungsi akan memanggil lenght. Yang kemudian mendefinisikan variabel req untuk lenght dam melakukan random choice yaitu pengocokan acak untuk kata motor.
\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figures/AIP/e16.PNG}
\caption{PermuteSentencesi Aip}
\label{Praktek}
\end{figure}

